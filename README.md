# MLflow-FastAPI Model Serving

This project provides a full **ML pipeline** using **MLflow** for model tracking and **FastAPI** for deployment.

## ğŸš€ Features
- Train and log models using MLflow
- Serve models via FastAPI
- Track experiments and metrics
- REST API for predictions

---

## ğŸ›  Installation

### 1ï¸âƒ£ **Set Up Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate    # Windows
```

### 2ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Run MLflow Tracking Server**
```bash
mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host(http://127.0.0.1/)--port 5000
```

---

## ğŸ“Š Training and Logging Model
Run the `train.py` script to train and log the model:
```bash
python train.py
```

This will:
- Train a machine learning model
- Log the model and metrics in MLflow

---

## ğŸ”¥ Deploy Model with FastAPI
Start the FastAPI server to serve predictions:
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

---

## ğŸ“¡ API Endpoints
### ğŸ”¹ **Health Check**
```http
GET /
```
Response:
```json
{"message": "ML Model Serving is Running!"}
```

### ğŸ”¹ **Predict**
```http
POST /predict
```
#### **Request (JSON)**
```json
{
  "feature1": 1.2,
  "feature2": 3.4
}
```
#### **Response (JSON)**
```json
{
  "prediction": 0.87
}
```

---

## ğŸ— Project Structure
```
MLflow-FastAPI-Serving/
â”œâ”€â”€ venv/               # Virtual environment
â”œâ”€â”€ app.py              # FastAPI server
â”œâ”€â”€ train.py            # Training script
â”œâ”€â”€ requirements.txt    # Dependencies        
â”œâ”€â”€ mlruns/             # Stored ML models
â””â”€â”€ README.md           # Documentation
```

---
## MLflow Experiment Tracking

Below is a screenshot of the MLflow UI showing experiment runs:

<img width="956" alt="image" src="https://github.com/user-attachments/assets/9fa3cd32-9f70-4d71-8ad9-a089a346f362" />


----

## ğŸ’¡ Next Steps
- ğŸ” Improve model performance
- ğŸ“¦ Containerize with Docker
- ğŸš€ Deploy on cloud (AWS/GCP)


